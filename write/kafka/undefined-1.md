# 카프카 기본 개념

## 오픈소스 아파치 카프카 생태계

커넥트, 프로튜서, 컨슈머, 스트림즈 는 kafka 가 제공하는 공식 java 로 구성된 라이브러리 이다.

<figure><img src="../../.gitbook/assets/image (6).png" alt=""><figcaption></figcaption></figure>

프로듀서 : 데이터 전송

컨슈머 : 데이터를 소비하는

스트림즈 : 토픽의 데이터를 가공해서 다시 토픽에 넣을 때

커넥트(소스) :  3rd party 모듈들의 프로듀스 하는 역할

커넥트(싱크) : 3rd party 모듈들의 컨슈머 하는 역할

## 카프카 브로커와 클러스터

* 카프카 브로커 서버 1대로도 기본 기능이 실행되지만 데이터를 아전하게 보관하고 처리하기 위해 3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 운영한다.
* 카프카 클러스터로 묶인 브로커들은 프로듀서가 보낸 데이터를 안전하게 분산 저장하고 복제하는 역할을 수행한다.

## 카프카 클러스터와 주키퍼

주키퍼(Zookeeper)는 분산 환경에서 노드 간의 정보 공유, 락(Lock), 이벤트 등 보조 기능을 제공하는 프레임워크다. 아파치 하둡 프로젝트에서는 프로젝트 이름들이 코끼리([hadoop](https://terms.naver.com/entry.nhn?docId=3386322\&ref=y)), 거북이(chukwa), 돼지(pig) 등과 같이 동물들 이름이 많다. 동물 사육사라는 의미대로 주키퍼는 그림 4와 같이 하둡 분산 처리 시스템을 일괄적으로 관리해주는 시스템이다.

주키퍼는 아래와 같이네임서비스를 통해 하나의 서버만 서비스를 수행하지 않고 알맞게 분산해 각각의 클라이언트들이 동시 작업할 수 있도록 지원하여 부하를 분산시킨다. 또한 락(lock)을 통해 하나의 서버에서 처리된 결과가 또 다른 서버들과 동기화할 수 있도록 한다.

<figure><img src="../../.gitbook/assets/image (46).png" alt=""><figcaption></figcaption></figure>

**\[네이버 지식백과]** [Oozie / Hcatalog / Zookeeper](https://terms.naver.com/entry.naver?docId=3386319) (국립중앙과학관 - 빅데이터)

## 카프카 브로커의 역할들

### 컨트롤러

* 클러스터의 다수 브로커 중 한 대가 컨트롤러의 역할을 한다.&#x20;
* 컨트롤러는 다른 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배한다.

### 데이터 삭제

* 카프카는 다른 메세진 플랫폼과는 다르게 컨슈머가 데이터를 가져가더라도 토픽의 데이터는 삭제되지는 않는다.
* 오직 브로커만 데이터를 삭제할 수 있다.
* 데이터삭제는 파일 단위로 이루어지는데 이 단위를 '로그 세그먼트' 라고한다.
* 이 세그먼트에는 다수의 데이터가 들어 있기 때문에 일반적인 데이터베이스처럼 데이터를 선별해서 삭제할 수 없다.

### 컨슈머 오프셋 저장

* 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋한다.
* 커밋한 오프셋은 \_\_consumer\_offset 토픽에 저장한다.
* 여기에 저장된 오프셋을 토대로 다음 레코드를 가져가서 처리함

### 그룹 코디네이터

* 코디네이터 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할

## 브로커 로그와 세그먼트

### 브로커의 역할 - 데이터의 저장

* 카프카를 실행할 때 config/server.properties 의 log.dir 옵션에 정의한 디렉토리에 데이터를 저장한다.
* log에는 메시지와 메타데이터를 저장한다.
* index 는 메시지의 오프셋을 인덱싱한 정보를 담은 파일이다.

### 로그와 세그먼트

## 복제(replication)

* 데이터 복제는 카프카를 장애 허용 시스템으로 동작하도록 하는 원동력이다.
* 복제의 이유는 클러스터로 묶인 브로커 중 일부에 장애가 발생하더라도 데이터를 유실하지 않고 안전하게 사용하기 위함.

## 토픽과 파티션

* 토픽 : 카프카에서 데이터를 구분하기위해 사용하는 단위.
  * 1개이상의 파티션을 소유
* 레코드 : 프로듀서가 보낸 데이터들이 들어가 저장되는 데이터.

### 토픽 생성 시 파티션이 배치되는 방법

파티션이 5개인 토픽을 생성했을 경우 아래와 같이 0번 브로커로부터 시작하여 round-robin 방식으로 리더파티션들이 생성된다. 카프카 클라이언트는 리더 파티션이 있는 브로커와 통신하여 데이터를 주고 받으므로 여러 브로커에 골고루 네트워크 통신을 하게 된다.

<figure><img src="../../.gitbook/assets/image (45).png" alt=""><figcaption></figcaption></figure>

### 파티션 개수와 컨슈머 개수의 처리량

* 파티션은 카프카 병렬 처리의 핵심
* 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리 할 수 있도록 매칭
* 하나의 파티션에는 하나의 컨슈머만 할당될 수 있다.
* 컨슈머의 개수와 파티션늘개수도려늘려스케일 아웃 하는 것이  제이 좋은 방

<figure><img src="../../.gitbook/assets/image (44).png" alt=""><figcaption></figcaption></figure>

## 레코드

* 레코드는 타임스탬프, 헤더, 메시지 키, 메시지 값, 오프셋으로 구성되어 있다. 프로듀서가 생성한 레코드가 브로커로 전송되면 오프셋과 타임스템프가 지정되어 저장된다.
* 브로커에 한번 적재된 레코드는 수정할 수 없고 로그 리텐션 기간 또는 용량에 따라서만 삭제됨.

<figure><img src="../../.gitbook/assets/image (43).png" alt=""><figcaption></figcaption></figure>

* timestamp
  * 브로커 적재 시간 또는 생성 시간으로 설정 가능
* offset
  * 0부터 1씩 증가. 컨슈머는 오프셋을 기반으로 데이터를 처리
* header&#x20;
  * 스키마 같이 데이터 프로세싱에 참고할만한 정보를 담아서 사용할 수 있다. http 헤더와 비슷한 용도
* key
  * 메시지 값의 분류하기 위한 용도. 이를 파티셔닝 이라고 부른다. 어느 파티션에 들어갈지 지정할 수 있는 것.&#x20;
    * null 이 default 이고, 이 때 round-robin 으로 파티션에 들어감
* value
  * 실질적으로 처리할 데이터가 담기는 공간. 메시지 값의 포맷은 제네릭으로 사용자에 의해 지정됨.
  * 브로커에 저장된 레코드의 메시지 값은 어떤 포멧으로 직렬화되어 저장되었는지 알 수 없기 때문에 컨슈머는 미리 역직렬화 포멧을 알고 있어야 한다.

## 질문

* 카프카는 어떤 경우에 사용하고 왜? 어디서? 컨슈머의 주체는 뭐지?
* 파티션과 컨슈머는 왜 1:1 이고 컨슈머는 데이터를 하나의 파티션으로부터 받아서 가공하는 주체? 아니면 디바이스?

{% file src="../../.gitbook/assets/섹션2 카프카 기본 개념 설명.pdf" %}
